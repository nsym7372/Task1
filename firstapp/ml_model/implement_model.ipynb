{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.6 64-bit ('base': conda)",
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "e0fa32df09240578d33618ae9f55978bb244099e41dcb6a617524ee4978a2ed6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpath = glob('animal_images/ゴリラ/*.jpg')\n",
    "epath = glob('animal_images/ゾウ/*.jpg')\n",
    "ppath = glob('animal_images/パンダ/*.jpg')\n",
    "bpath = glob('animal_images/ホッキョクグマ/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total = len(gpath)\n",
    "n_train = int(n_total * 0.7)\n",
    "n_test = int(n_total * 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = gpath[:n_train] + epath[:n_train] + ppath[:n_train] + bpath[:n_train]\n",
    "test_paths = gpath[n_train:] + epath[n_train:] + ppath[n_train:] + bpath[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "84"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "len(train_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imsize = 256\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = datasets.ImageFolder('animal_images', transform)\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn_model import Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train), len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path=None, transform=None):\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "\n",
    "        #画像のラベルをファイル名から抜き出す\n",
    "        for p in path:\n",
    "            if 'ゴリラ' in p:\n",
    "                label = 0\n",
    "            elif 'ゾウ' in p:\n",
    "                label = 1\n",
    "            elif 'パンダ' in p:\n",
    "                label = 2\n",
    "            else:\n",
    "                label = 3\n",
    "            self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(list(self.path))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #index番目の画像を読み込み\n",
    "        path = self.path[index]\n",
    "        img = Image.open(path)\n",
    "\n",
    "        #前処理\n",
    "        img_transformed = self.transform(img)\n",
    "\n",
    "        #index番目のラベルを読み込み\n",
    "        label = self.labels[index]\n",
    "\n",
    "        return img_transformed, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\n\n  | Name | Type        | Params\n-------------------------------------\n0 | conv | Conv2d      | 84    \n1 | pool | MaxPool2d   | 0     \n2 | bn   | BatchNorm1d | 24 K  \n3 | fc1  | Linear      | 1 M   \n4 | fc2  | Linear      | 404   \nEpoch 0:  60%|██████    | 3/5 [00:04<00:02,  1.43s/it, loss=6.463, v_num=14]\nValidating: 0it [00:00, ?it/s]\u001b[A\nEpoch 0:  80%|████████  | 4/5 [00:04<00:01,  1.22s/it, loss=6.463, v_num=14]\nEpoch 0: 100%|██████████| 5/5 [00:05<00:00,  1.01s/it, loss=6.463, v_num=14]\nEpoch 1:  60%|██████    | 3/5 [00:03<00:02,  1.04s/it, loss=4.458, v_num=14]\nValidating: 0it [00:00, ?it/s]\u001b[A\nEpoch 1:  80%|████████  | 4/5 [00:03<00:00,  1.07it/s, loss=4.458, v_num=14]\nEpoch 1: 100%|██████████| 5/5 [00:03<00:00,  1.27it/s, loss=4.458, v_num=14]\nEpoch 2:  60%|██████    | 3/5 [00:03<00:02,  1.05s/it, loss=3.493, v_num=14]\nValidating: 0it [00:00, ?it/s]\u001b[A\nEpoch 2:  80%|████████  | 4/5 [00:03<00:00,  1.05it/s, loss=3.493, v_num=14]\nEpoch 2: 100%|██████████| 5/5 [00:04<00:00,  1.25it/s, loss=3.493, v_num=14]\nEpoch 3:  60%|██████    | 3/5 [00:03<00:02,  1.01s/it, loss=3.047, v_num=14]\nValidating: 0it [00:00, ?it/s]\u001b[A\nEpoch 3:  80%|████████  | 4/5 [00:03<00:00,  1.09it/s, loss=3.047, v_num=14]\nEpoch 3: 100%|██████████| 5/5 [00:03<00:00,  1.31it/s, loss=3.047, v_num=14]\nEpoch 4:  60%|██████    | 3/5 [00:03<00:02,  1.08s/it, loss=2.582, v_num=14]\nValidating: 0it [00:00, ?it/s]\u001b[A\nEpoch 4:  80%|████████  | 4/5 [00:03<00:00,  1.05it/s, loss=2.582, v_num=14]\nEpoch 4: 100%|██████████| 5/5 [00:03<00:00,  1.25it/s, loss=2.582, v_num=14]\nEpoch 5:  60%|██████    | 3/5 [00:03<00:02,  1.04s/it, loss=2.265, v_num=14]\nValidating: 0it [00:00, ?it/s]\u001b[A\nEpoch 5:  80%|████████  | 4/5 [00:03<00:00,  1.04it/s, loss=2.265, v_num=14]\nEpoch 5: 100%|██████████| 5/5 [00:04<00:00,  1.24it/s, loss=2.265, v_num=14]\nEpoch 6:  60%|██████    | 3/5 [00:03<00:02,  1.11s/it, loss=2.010, v_num=14]\nValidating: 0it [00:00, ?it/s]\u001b[A\nEpoch 6:  80%|████████  | 4/5 [00:03<00:00,  1.01it/s, loss=2.010, v_num=14]\nEpoch 6: 100%|██████████| 5/5 [00:04<00:00,  1.22it/s, loss=2.010, v_num=14]\nEpoch 7:  60%|██████    | 3/5 [00:03<00:02,  1.11s/it, loss=1.114, v_num=14]\nValidating: 0it [00:00, ?it/s]\u001b[A\nEpoch 7:  80%|████████  | 4/5 [00:03<00:00,  1.01it/s, loss=1.114, v_num=14]\nEpoch 7: 100%|██████████| 5/5 [00:04<00:00,  1.23it/s, loss=1.114, v_num=14]\nEpoch 8:  60%|██████    | 3/5 [00:03<00:02,  1.10s/it, loss=0.801, v_num=14]\nValidating: 0it [00:00, ?it/s]\u001b[A\nEpoch 8:  80%|████████  | 4/5 [00:03<00:00,  1.03it/s, loss=0.801, v_num=14]\nEpoch 8: 100%|██████████| 5/5 [00:04<00:00,  1.22it/s, loss=0.801, v_num=14]\nEpoch 9:  60%|██████    | 3/5 [00:03<00:02,  1.04s/it, loss=0.552, v_num=14]\nValidating: 0it [00:00, ?it/s]\u001b[A\nEpoch 9:  80%|████████  | 4/5 [00:03<00:00,  1.06it/s, loss=0.552, v_num=14]\nEpoch 9: 100%|██████████| 5/5 [00:03<00:00,  1.29it/s, loss=0.552, v_num=14]\nEpoch 10:  60%|██████    | 3/5 [00:03<00:02,  1.12s/it, loss=0.425, v_num=14]\nValidating: 0it [00:00, ?it/s]\u001b[A\nEpoch 10:  80%|████████  | 4/5 [00:04<00:01,  1.02s/it, loss=0.425, v_num=14]\nEpoch 10: 100%|██████████| 5/5 [00:04<00:00,  1.20it/s, loss=0.425, v_num=14]\nEpoch 11:  60%|██████    | 3/5 [00:03<00:02,  1.12s/it, loss=0.402, v_num=14]\nValidating: 0it [00:00, ?it/s]\u001b[A\nEpoch 11:  80%|████████  | 4/5 [00:04<00:01,  1.01s/it, loss=0.402, v_num=14]\nEpoch 11: 100%|██████████| 5/5 [00:04<00:00,  1.21it/s, loss=0.402, v_num=14]\nEpoch 12:  60%|██████    | 3/5 [00:03<00:02,  1.16s/it, loss=0.322, v_num=14]\nValidating: 0it [00:00, ?it/s]\u001b[A\nEpoch 12:  80%|████████  | 4/5 [00:04<00:01,  1.04s/it, loss=0.322, v_num=14]\nEpoch 12: 100%|██████████| 5/5 [00:04<00:00,  1.17it/s, loss=0.322, v_num=14]\nEpoch 13:  60%|██████    | 3/5 [00:03<00:02,  1.15s/it, loss=0.328, v_num=14]\nValidating: 0it [00:00, ?it/s]\u001b[A\nEpoch 13:  80%|████████  | 4/5 [00:04<00:01,  1.03s/it, loss=0.328, v_num=14]\nEpoch 13: 100%|██████████| 5/5 [00:04<00:00,  1.17it/s, loss=0.328, v_num=14]\nEpoch 14:  60%|██████    | 3/5 [00:03<00:02,  1.13s/it, loss=0.525, v_num=14]\nValidating: 0it [00:00, ?it/s]\u001b[A\nEpoch 14:  80%|████████  | 4/5 [00:04<00:01,  1.06s/it, loss=0.525, v_num=14]\nEpoch 14: 100%|██████████| 5/5 [00:04<00:00,  1.15it/s, loss=0.525, v_num=14]\nEpoch 15:  60%|██████    | 3/5 [00:03<00:02,  1.18s/it, loss=0.524, v_num=14]\nValidating: 0it [00:00, ?it/s]\u001b[A\nEpoch 15:  80%|████████  | 4/5 [00:04<00:01,  1.05s/it, loss=0.524, v_num=14]\nEpoch 15: 100%|██████████| 5/5 [00:04<00:00,  1.15it/s, loss=0.524, v_num=14]\nEpoch 16:  60%|██████    | 3/5 [00:03<00:02,  1.14s/it, loss=0.635, v_num=14]\nValidating: 0it [00:00, ?it/s]\u001b[A\nEpoch 16:  80%|████████  | 4/5 [00:04<00:01,  1.01s/it, loss=0.635, v_num=14]\nEpoch 16: 100%|██████████| 5/5 [00:04<00:00,  1.20it/s, loss=0.635, v_num=14]\nEpoch 17:  60%|██████    | 3/5 [00:03<00:02,  1.15s/it, loss=0.521, v_num=14]\nValidating: 0it [00:00, ?it/s]\u001b[A\nEpoch 17:  80%|████████  | 4/5 [00:04<00:01,  1.03s/it, loss=0.521, v_num=14]\nEpoch 17: 100%|██████████| 5/5 [00:04<00:00,  1.18it/s, loss=0.521, v_num=14]\nEpoch 18:  60%|██████    | 3/5 [00:03<00:02,  1.05s/it, loss=0.505, v_num=14]\nValidating: 0it [00:00, ?it/s]\u001b[A\nEpoch 18:  80%|████████  | 4/5 [00:03<00:00,  1.05it/s, loss=0.505, v_num=14]\nEpoch 18: 100%|██████████| 5/5 [00:03<00:00,  1.27it/s, loss=0.505, v_num=14]\nEpoch 19:  60%|██████    | 3/5 [00:03<00:02,  1.13s/it, loss=0.449, v_num=14]\nValidating: 0it [00:00, ?it/s]\u001b[A\nEpoch 19:  80%|████████  | 4/5 [00:04<00:01,  1.02s/it, loss=0.449, v_num=14]\nEpoch 19: 100%|██████████| 5/5 [00:04<00:00,  1.19it/s, loss=0.449, v_num=14]\n                                                         \u001b[ASaving latest checkpoint..\nEpoch 19: 100%|██████████| 5/5 [00:04<00:00,  1.19it/s, loss=0.449, v_num=14]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# バッチサイズ\n",
    "batch_size = 32\n",
    "num_workers = 0\n",
    "\n",
    "\n",
    "\n",
    "train = MyDataset(path=train_paths, transform=transform) \n",
    "val = MyDataset(path=test_paths, transform=transform)\n",
    "\n",
    "# train[30]\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size, num_workers=num_workers, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size, num_workers=num_workers)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=20)\n",
    "model = Net()\n",
    "\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'val_loss': tensor(32.0865),\n 'val_acc': tensor(0.4219),\n 'loss': tensor(0.1160)}"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "trainer.callback_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.to('cpu').state_dict(), 'trained.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "graph(%input.1 : Float(1, 3, 128, 128),\n      %conv.weight : Float(3, 3, 3, 3),\n      %conv.bias : Float(3),\n      %bn.weight : Float(12288),\n      %bn.bias : Float(12288),\n      %bn.running_mean : Float(12288),\n      %bn.running_var : Float(12288),\n      %fc1.weight : Float(100, 12288),\n      %fc1.bias : Float(100),\n      %fc2.weight : Float(4, 100),\n      %fc2.bias : Float(4),\n      %27 : Long(1)):\n  %12 : Float(1, 3, 128, 128) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input.1, %conv.weight, %conv.bias) # C:\\Users\\image\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:350:0\n  %13 : Float(1, 3, 128, 128) = onnx::Relu(%12) # C:\\Users\\image\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1063:0\n  %14 : Float(1, 3, 64, 64) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%13) # C:\\Users\\image\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:539:0\n  %15 : Tensor = onnx::Shape(%14)\n  %16 : Tensor = onnx::Constant[value={0}]()\n  %17 : Long() = onnx::Gather[axis=0](%15, %16) # c:\\Users\\image\\Desktop\\長期コース講座\\20200920\\task\\firstapp\\ml_model\\cnn_model.py:71:0\n  %19 : Tensor = onnx::Unsqueeze[axes=[0]](%17)\n  %21 : Tensor = onnx::Concat[axis=0](%19, %27)\n  %22 : Float(1, 12288) = onnx::Reshape(%14, %21) # c:\\Users\\image\\Desktop\\長期コース講座\\20200920\\task\\firstapp\\ml_model\\cnn_model.py:71:0\n  %23 : Float(1, 12288) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%22, %bn.weight, %bn.bias, %bn.running_mean, %bn.running_var) # C:\\Users\\image\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1923:0\n  %24 : Float(1, 100) = onnx::Gemm[alpha=1., beta=1., transB=1](%23, %fc1.weight, %fc1.bias) # C:\\Users\\image\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1610:0\n  %25 : Float(1, 100) = onnx::Relu(%24) # C:\\Users\\image\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1063:0\n  %26 : Float(1, 4) = onnx::Gemm[alpha=1., beta=1., transB=1](%25, %fc2.weight, %fc2.bias) # C:\\Users\\image\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1610:0\n  return (%26)\n\n"
    }
   ],
   "source": [
    "y = Variable(train[0][0].unsqueeze(0))\n",
    "torch.onnx.export(model, y, 'model.onnx', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}